Test Model for Immersive Video

This repository includes the current reference software of MPEG Immersive Video 
project, part of the future MPEG-I standard (ISO/IEC 23090) dedicated to 
immersive media technology. This standard part 12 will enable visual media 
consumption with large or very large field of view – along the 3 degrees of 
viewer head’s orientation yaw, pitch and roll - and with a sense of parallax
within a small head displacement volume along x, y and z axis for improved 
viewer visual comfort. The related use case is therefore also known as 3DoF+. 
Such a 3DoF+ bitstream is based on legacy HEVC coding technology preceded by a
preprocessing whose decoding requires a small number of metadata specified in 
the current draft “Metadata for Immersive Video (MIV) specification” document.
This related Test Model software for Immersive Video (TMIV) gets as input a 
multiplicity of texture + depth videos – as it would be generated by a camera 
rig and a depth computation workflow –, sets up the whole chain of
preprocessing, HM video encoding, HM video decoding and post-processing, and 
outputs images according to viewport configuration. It can be used to compute 
objective metrics as defined by the latest version of “Common Test Conditions 
for Immersive Video” document and can also be used to generate videos along 
predefined navigation path for subjective evaluations. The list of parameters 
for the TMIV configuration and the used algorithms in each TMIV block are 
detailed and explained in the current version of the “Test Model for 
Immersive Video” document.

All mentioned documents are or will be publically accessible on
https://mpeg.chiariglione.org/.

The software is ISO C++17 conformant and does not require external libraries. 
Core experiments are expected to include the reference software as a subproject
and introduce new components. Alternatively core experiments may fork the test model.
Contributions should be in the form of git pull requests to the MPEG-internal project.
